{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOMPGkHazGDvF4AoJuR7BJK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","df = pd.read_csv('/content/drive/MyDrive/Kwargs/022. esg관련도 필터/업데이트/A2_remaster_combined_ANONYMIZED.csv')\n","df['esg_score'].value_counts()"],"metadata":{"id":"W8LIa5gkUYac"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":303},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1727426808632,"user":{"displayName":"백현지","userId":"02510457579208942463"},"user_tz":-540},"id":"QYrVsH8-8IsY","outputId":"bdeb3922-d199-4705-c4a5-be846b362035"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["esg_score_6\n","0.0    24031\n","0.4     8022\n","0.2     6535\n","0.6     3871\n","0.8     2591\n","1.0      559\n","Name: count, dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","    </tr>\n","    <tr>\n","      <th>esg_score_6</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0.0</th>\n","      <td>24031</td>\n","    </tr>\n","    <tr>\n","      <th>0.4</th>\n","      <td>8022</td>\n","    </tr>\n","    <tr>\n","      <th>0.2</th>\n","      <td>6535</td>\n","    </tr>\n","    <tr>\n","      <th>0.6</th>\n","      <td>3871</td>\n","    </tr>\n","    <tr>\n","      <th>0.8</th>\n","      <td>2591</td>\n","    </tr>\n","    <tr>\n","      <th>1.0</th>\n","      <td>559</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{},"execution_count":4}],"source":["# Initial relabeling based on the updated criteria\n","def updated_relabel(value):\n","    if 1.0 >= value >= 0.9:\n","        return '상당히 관련있음'\n","    elif value == 0.8:\n","        return '적절히 관련있음'\n","    elif 0.7 >= value >= 0.6:\n","        return '약간 관련있음'\n","    elif 0.5 >= value >= 0.3:\n","        return '거의 관련없음'\n","    elif value == 0.2:\n","        return '상당히 관련없음'\n","    else:\n","        return '완전히 관련없음'\n","\n","# Apply the updated relabeling function\n","df['esg_score_6'] = df['esg_score'].apply(updated_relabel)\n","\n","# Continuous encoding based on 0.2 intervals\n","continuous_mapping = {\n","    '상당히 관련있음': 1.0,\n","    '적절히 관련있음': 0.8,\n","    '약간 관련있음': 0.6,\n","    '거의 관련없음': 0.4,\n","    '상당히 관련없음': 0.2,\n","    '완전히 관련없음': 0.0\n","}\n","\n","# Apply the continuous mapping\n","df['esg_score_6'] = df['esg_score_6'].map(continuous_mapping)\n","\n","df['esg_score_6'].value_counts()"]},{"cell_type":"code","source":["# 필요한 라이브러리 불러오기\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, Dataset\n","from transformers import ElectraTokenizer, ElectraForSequenceClassification, get_linear_schedule_with_warmup\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","import os\n","from torch.cuda.amp import GradScaler, autocast\n","from tqdm import tqdm\n","import torch.optim as optim\n","\n","# GPU 설정\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Hugging Face 모델 캐시 경로를 Google Drive로 설정\n","os.environ['TRANSFORMERS_CACHE'] = '/content/drive/MyDrive/Kwargs/022. esg관련도 필터/업데이트/hf_cache'\n","\n","# 데이터셋 클래스 정의\n","class TextDataset(Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]).to(device) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx]).to(device)\n","        return item\n","\n","# 라벨 클래스 수 계산 및 인덱스 매핑\n","unique_labels = sorted(df['esg_score_6'].unique())  # num_classes 변수 정의\n","num_classes = len(unique_labels)\n","label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n","df['label_indices'] = df['esg_score_6'].map(label_to_index)\n","\n","# Train-Test Split\n","train_texts = df['full_text'][:int(0.8 * len(df))].tolist()\n","val_texts = df['full_text'][int(0.8 * len(df)):].tolist()\n","train_labels_indices = df['label_indices'][:int(0.8 * len(df))].tolist()\n","val_labels_indices = df['label_indices'][int(0.8 * len(df)):].tolist()\n","\n","# 하이퍼파라미터 설정\n","learning_rate = 2e-4\n","batch_size = 32\n","epochs = 3\n","max_length = 512\n","max_weight = 4.0\n","\n","# 클래스별 빈도 계산 및 가중치 설정\n","label_counts = df['label_indices'].value_counts().sort_index()\n","class_freq = label_counts.values\n","class_weights = 1.0 / class_freq\n","class_weights = torch.tensor([min(weight, max_weight) for weight in class_weights], dtype=torch.float).to(device)\n","\n","# 토크나이저 및 모델 불러오기\n","tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-discriminator\")\n","model = ElectraForSequenceClassification.from_pretrained(\"monologg/koelectra-base-discriminator\", num_labels=num_classes)\n","model.to(device)\n","\n","# Train-Test 데이터셋을 미리 토크나이징\n","train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=max_length)\n","val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=max_length)\n","\n","# 데이터셋 생성\n","train_dataset = TextDataset(train_encodings, train_labels_indices)\n","val_dataset = TextDataset(val_encodings, val_labels_indices)\n","\n","# 데이터로더 생성\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","\n","# 손실 함수 및 옵티마이저 설정 (PyTorch의 AdamW 사용)\n","loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n","optimizer = optim.AdamW(model.parameters(), lr=learning_rate)  # PyTorch의 AdamW 사용\n","total_steps = len(train_loader) * epochs\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n","\n","# Mixed Precision Training을 위한 GradScaler\n","scaler = GradScaler()\n","\n","# 학습 함수 정의\n","def train_model():\n","    model.train()\n","    total_loss = 0\n","    for batch in tqdm(train_loader, desc=\"Training\"):\n","        optimizer.zero_grad()\n","        with autocast():\n","            outputs = model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'], labels=batch['labels'])\n","            loss = outputs.loss\n","            total_loss += loss.item()\n","\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","        scheduler.step()\n","\n","    torch.cuda.empty_cache()\n","\n","    avg_loss = total_loss / len(train_loader)\n","    return avg_loss\n","\n","# 평가 함수 정의\n","def evaluate_model():\n","    model.eval()\n","    val_labels_list, val_preds_list = [], []\n","    with torch.no_grad():\n","        for batch in tqdm(val_loader, desc=\"Evaluating\"):\n","            with autocast():\n","                outputs = model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\n","                logits = outputs.logits\n","                _, preds = torch.max(logits, dim=1)\n","                val_labels_list.extend(batch['labels'].cpu().numpy())\n","                val_preds_list.extend(preds.cpu().numpy())\n","\n","    torch.cuda.empty_cache()\n","\n","    return val_labels_list, val_preds_list\n","\n","# 학습 루프\n","for epoch in range(epochs):\n","    print(f\"Epoch {epoch + 1}/{epochs}\")\n","    train_loss = train_model()\n","    val_labels_list, val_preds_list = evaluate_model()\n","    accuracy = accuracy_score(val_labels_list, val_preds_list)\n","    precision = precision_score(val_labels_list, val_preds_list, average='weighted')\n","    recall = recall_score(val_labels_list, val_preds_list, average='weighted')\n","    f1 = f1_score(val_labels_list, val_preds_list, average='weighted')\n","\n","    print(f\"Train Loss: {train_loss:.4f}\")\n","    print(f\"Validation Results - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")\n","\n","# 모델 및 토크나이저 저장\n","save_directory = '/content/drive/MyDrive/Kwargs/022. esg관련도 필터/업데이트'\n","if not os.path.exists(save_directory):\n","    os.makedirs(save_directory)\n","\n","model_path = os.path.join(save_directory, \"A2-14_0927\")\n","torch.save(model.state_dict(), model_path)\n","tokenizer.save_pretrained(save_directory)\n","\n","print(f\"모델과 토크나이저가 저장되었습니다: {save_directory}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":528,"referenced_widgets":["2f45c540c23445d0b0ef86848c9a7a54","b7d93d3fea3042acb50c26bd11002440","caa1ce1400dd47039d13d2108809c6ff","fb26fd75b20f4ff3b38653a52069198a","c22a6ba08fa144f7990d76706759ff64","564c00f0b413429f81c37d17330848b1","4448c5cb238d4a2cb2f8b5d625676c24","1883aa2f0e5f4dce82f203d9ce6f20a1","975db2d05a894490a4eb628ad93eb157","b7f158bf28194a55bf6c1f9fe74b6042","20c9118457e04fe287103beaa6b4d5b2","399e92c0a9924f3e806d4dc2a631e306","bbc5651eabeb400da10280022073940f","133feb604520406c827430787517e931","90c2663dc8e34f9c83cbf2fc519764dd","53ea37bc543c4c09aadbb8bd47caf561","aa113cd00a0840f79d3942a46e3158fa","69bfa3aec51d4d038b6283660d73eee4","08663593b3e24e93ab1096c052f54b71","5e800e90609a4c3781abf9bf21042537","f6cb21a65368421683c4a580327971d7","a8d692088d9e4fa887df8a439f365bb5","a80761cab18e4e0ebfa2f5cd43442d7b","f3d79b98d0ac4e94890bed4f08399704","34d9b064fdf742a8b0ef587d5b7ee76b","68e045f366854560b51ca6cb9201844f","27c307065c4e464b9031e4c729ccbd5c","7f19aa0d9c81400b9c7602c20466561e","034563900f174048b92744faeb5c084e","0033bb11e48844efbf6e7a5554db9035","75004f66a97a4016af3fbd481422cec9","79b2702b83d24ca3b96a54adcb314c81","6247f536e1f64b9395c43ce4ccb906d4","45a3c616f6814333af28abcc21db93ed","c335318febd94c849decc18a3a4bbdba","977bf8fad91f491497ebf18b41f8ad5e","46cb8fbd8d5c482f964cd8d62f7e1cd2","110ae14723154c9a8ed5b681cb48ab65","dc436b313dc349de8ffd91a1d1bec481","60aa64c7ac484c9291ccf0f7adc86c9e","3c21270650ea44b5ae2e51cf40c0d558","765e89882ab84061b8b27f1a7e083698","80a3dcf27ec0442ca571a5019bdc9cc6","e3f1a9bfbe5a4cbd93373d800ede5191"]},"id":"9ADJRfqaQqem","outputId":"4bd5fd45-f23e-424d-baca-81c13c40a96d"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2f45c540c23445d0b0ef86848c9a7a54","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/51.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"399e92c0a9924f3e806d4dc2a631e306","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/279k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a80761cab18e4e0ebfa2f5cd43442d7b","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/467 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"45a3c616f6814333af28abcc21db93ed","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","<ipython-input-5-aa6f8786fdab>:81: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  scaler = GradScaler()\n","/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/3\n"]},{"output_type":"stream","name":"stderr","text":["Training:   0%|          | 0/4561 [00:00<?, ?it/s]<ipython-input-5-aa6f8786fdab>:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with autocast():\n","/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py:265: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n","  warnings.warn(\n","Training:   7%|▋         | 310/4561 [24:27<5:32:23,  4.69s/it]"]}]}]}