{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"wVO8VRZ3Nm1f"},"outputs":[],"source":["import pandas as pd\n","import os\n","import re\n","from tqdm.auto import tqdm\n","import shutil\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28227,"status":"ok","timestamp":1728120899009,"user":{"displayName":"백현지","userId":"02510457579208942463"},"user_tz":-540},"id":"EkT3-udEL1zD","outputId":"4d5674b6-2e17-4ed4-926f-e36d14503968"},"outputs":[{"output_type":"stream","name":"stdout","text":["                                           full_text  \\\n","0  “주문량 넘쳐 규모 7배이상 확대”유럽시장 공략에 본격 투자 나서 LG화학-삼성SD...   \n","1  머니투데이 고석용 기자 사람인 구직자 대상 조사 2위에 카카오, 5위 네이버구직자들...   \n","2  입사 선호기업 상위권에 IT·벤처기업들이 도약하는 양상이다.구인구직 매칭플랫폼 사람...   \n","3   '코스피 2196·코스닥 738' 코스피 지수가 2200선 안착에 또다시 실패했다...   \n","4  -올해 주총 집중도 지난해 대비 완화-26일과 27일 주총 집중예상일 추가 지정 검...   \n","\n","                                             content  \n","0  “주문량 넘쳐 규모 7배이상 확대”유럽시장 공략에 본격 투자 나서 LG화학-삼성SD...  \n","1  머니투데이 고석용 기자 사람인 구직자 대상 조사 2위에 카카오, 5위 네이버구직자들...  \n","2  입사 선호기업 상위권에 IT·벤처기업들이 도약하는 양상이다.구인구직 매칭플랫폼 사람...  \n","3   '코스피 2196·코스닥 738' 코스피 지수가 2200선 안착에 또다시 실패했다...  \n","4  -올해 주총 집중도 지난해 대비 완화-26일과 27일 주총 집중예상일 추가 지정 검...  \n"]}],"source":["# 각 기업에서 발생한 라벨 1의 개수를 추적하는 코드\n","data = pd.read_csv('/content/drive/MyDrive/Kwargs/020. 전처리/A0_Sports_Obituary_filterbase.csv')\n","\n","# 2. 'full_text' 컬럼이 비어 있는 경우 'content' 컬럼으로 대체\n","# pandas의 .fillna()를 사용하여 'full_text'가 비어있으면 'content' 컬럼의 값으로 채움\n","data['full_text'] = data['full_text'].fillna(data['content'])\n","data['full_text'] = data['content'].fillna(data['full_text'])\n","\n","# 3. 'full_text'가 비어있는 경우뿐만 아니라 값이 있지만 공백인 경우도 대체\n","# 공백이나 빈 문자열이 포함된 경우에도 'content' 값으로 대체\n","data['full_text'] = data.apply(lambda row: row['content'] if pd.isna(row['full_text']) or row['full_text'].strip() == \"\" else row['full_text'], axis=1)\n","data['content'] = data.apply(lambda row: row['full_text'] if pd.isna(row['content']) or row['content'].strip() == \"\" else row['content'], axis=1)\n","\n","# 결과 확인\n","print(data[['full_text', 'content']].head())\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":178},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1728120899009,"user":{"displayName":"백현지","userId":"02510457579208942463"},"user_tz":-540},"id":"kTfzTmxzZJ6y","outputId":"b62b169f-53b6-4d40-fb6e-06585f03e80a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["labelso\n","0    169559\n","1     12332\n","Name: count, dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","    </tr>\n","    <tr>\n","      <th>labelso</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>169559</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>12332</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{},"execution_count":22}],"source":["# 라벨 1의 데이터 추출 및 각 기업별로 라벨 1의 개수 세기\n","data['labelso'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5304,"status":"ok","timestamp":1728120904304,"user":{"displayName":"백현지","userId":"02510457579208942463"},"user_tz":-540},"id":"a8DHT9WuHJeT","outputId":"004fd6eb-c0e3-468f-c8dc-26b9ce3ca71f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.8)\n","Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.13.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"]}],"source":["!pip install datasets\n","!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c7hhx-VpWw7z"},"outputs":[],"source":["import pandas as pd\n","from transformers import ElectraTokenizer, ElectraForSequenceClassification, Trainer, TrainingArguments\n","from datasets import Dataset, DatasetDict\n","import torch\n","\n","\n","# 데이터가 'full_text'와 'labelso' 컬럼을 포함해야 함\n","# 만약 그렇지 않다면 적절한 전처리가 필요함\n","data = data[['full_text', 'labelso']]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1728120904305,"user":{"displayName":"백현지","userId":"02510457579208942463"},"user_tz":-540},"id":"XFJEmbijaAS-","outputId":"b5477d24-d634-42fa-e005-4590df781747"},"outputs":[{"output_type":"stream","name":"stdout","text":["labelso\n","1    12332\n","0    12332\n","Name: count, dtype: int64\n"]}],"source":["import pandas as pd\n","from sklearn.utils import resample\n","\n","# 라벨 1과 라벨 0을 분리\n","label_1 = data[data['labelso'] == 1]\n","label_0 = data[data['labelso'] == 0]\n","\n","# 라벨 1의 수에 맞춰 라벨 0을 랜덤하게 다운샘플링\n","label_0_downsampled = resample(label_0,\n","                               replace=False,  # 복원 없이 샘플링\n","                               n_samples=len(label_1),  # 라벨 1과 같은 수로 샘플링\n","                               random_state=42)  # 재현성을 위한 random state 설정\n","\n","# 다운샘플된 라벨 0과 라벨 1을 다시 결합\n","data_balanced = pd.concat([label_1, label_0_downsampled])\n","\n","# 데이터 섞기\n","data_balanced = data_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n","\n","# 결과 출력\n","print(data_balanced['labelso'].value_counts())\n"]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.utils import resample\n","from sklearn.model_selection import train_test_split\n","\n","# 라벨 컬럼명을 'label'로 변경\n","data = data.rename(columns={'labelso': 'label'})\n","\n","# 이후 프로세스에서 'label'을 사용하여 처리\n","label_1 = data[data['label'] == 1]\n","label_0 = data[data['label'] == 0]\n","\n","# 동일한 샘플링 및 파이프라인 유지\n","label_1_sampled = resample(label_1, n_samples=12332, random_state=42)\n","label_0_sampled = resample(label_0, n_samples=12332, random_state=42)\n","\n","data_balanced = pd.concat([label_1_sampled, label_0_sampled])\n","data_balanced = data_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n","\n","train_texts, val_texts, train_labels, val_labels = train_test_split(\n","    data_balanced['full_text'].tolist(),\n","    data_balanced['label'].tolist(),  # 'label'을 사용\n","    test_size=0.2,\n","    random_state=42\n",")\n"],"metadata":{"id":"WS5QyJehS-E5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import ElectraTokenizer, ElectraForSequenceClassification\n","from transformers import Trainer, TrainingArguments\n","import torch\n","\n","# Koelectra 모델과 토크나이저 로드\n","tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")\n","model = ElectraForSequenceClassification.from_pretrained(\"monologg/koelectra-base-v3-discriminator\", num_labels=2)\n","\n","# 데이터 토크나이징 (max_length = 256)\n","train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128)# 평균 토큰 길이 계산 = 775로 확인함\n","val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=128)\n","\n","class Dataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","    def __len__(self):\n","        return len(self.labels)\n","\n","train_dataset = Dataset(train_encodings, train_labels)\n","val_dataset = Dataset(val_encodings, val_labels)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G5ew3fjHS-DB","executionInfo":{"status":"ok","timestamp":1728123122294,"user_tz":-540,"elapsed":8226,"user":{"displayName":"백현지","userId":"02510457579208942463"}},"outputId":"6d84f67e-cb61-476a-ece9-6af334425b76"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n","Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["from transformers import ElectraTokenizer, ElectraForSequenceClassification\n","from transformers import Trainer, TrainingArguments\n","import torch\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","\n","# Koelectra 모델과 토크나이저 로드\n","tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")\n","model = ElectraForSequenceClassification.from_pretrained(\"monologg/koelectra-base-v3-discriminator\", num_labels=2)\n","\n","# 데이터 토크나이징 (max_length = 256)\n","train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=256)\n","val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=256)\n","\n","class Dataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","    def __len__(self):\n","        return len(self.labels)\n","\n","train_dataset = Dataset(train_encodings, train_labels)\n","val_dataset = Dataset(val_encodings, val_labels)\n","\n","# 모든 모델 파라미터를 연속적으로 변환하여 ValueError 방지\n","for param in model.parameters():\n","    param.data = param.data.contiguous()\n","\n","# 모델 평가를 위한 지표 정의\n","def compute_metrics(pred):\n","    labels = pred.label_ids\n","    preds = pred.predictions.argmax(-1)\n","    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n","    acc = accuracy_score(labels, preds)\n","    return {\n","        'accuracy': acc,\n","        'precision': precision,\n","        'recall': recall,\n","        'f1': f1,\n","    }\n","\n","# TrainingArguments 설정\n","training_args = TrainingArguments(\n","    output_dir='/content/drive/MyDrive/Kwargs/020. 전처리/A0_Sports_Obituary_koelectra',\n","    num_train_epochs=3,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    warmup_steps=500,\n","    weight_decay=0.01,\n","    eval_strategy=\"epoch\",  # deprecated 된 evaluation_strategy 대신 eval_strategy 사용\n","    save_strategy=\"epoch\",\n","    logging_dir='./logs',\n","    logging_steps=2,\n","    load_best_model_at_end=True,\n",")\n","\n","# Trainer 설정\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    compute_metrics=compute_metrics  # 평가 지표 추가\n",")\n","\n","# 모델 학습\n","trainer.train()\n","\n","# 학습 완료 후 모델 저장\n","model.save_pretrained('/content/drive/MyDrive/Kwargs/020. 전처리/A0_Sports_Obituary_koelectra')\n","tokenizer.save_pretrained('/content/drive/MyDrive/Kwargs/020. 전처리/A0_Sports_Obituary_koelectra')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":298},"id":"T49SbfoaS-AD","executionInfo":{"status":"ok","timestamp":1728125119621,"user_tz":-540,"elapsed":1997329,"user":{"displayName":"백현지","userId":"02510457579208942463"}},"outputId":"32c9bdf4-05e8-4178-f13d-6b22c9f62764"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [150/150 32:54, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.669900</td>\n","      <td>0.673256</td>\n","      <td>0.620000</td>\n","      <td>0.687500</td>\n","      <td>0.440000</td>\n","      <td>0.536585</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.625200</td>\n","      <td>0.616291</td>\n","      <td>0.660000</td>\n","      <td>0.880952</td>\n","      <td>0.370000</td>\n","      <td>0.521127</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.605000</td>\n","      <td>0.562249</td>\n","      <td>0.690000</td>\n","      <td>0.865385</td>\n","      <td>0.450000</td>\n","      <td>0.592105</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["('/content/drive/MyDrive/Kwargs/020. 전처리/A0_Sports_Obituary_koelectra/tokenizer_config.json',\n"," '/content/drive/MyDrive/Kwargs/020. 전처리/A0_Sports_Obituary_koelectra/special_tokens_map.json',\n"," '/content/drive/MyDrive/Kwargs/020. 전처리/A0_Sports_Obituary_koelectra/vocab.txt',\n"," '/content/drive/MyDrive/Kwargs/020. 전처리/A0_Sports_Obituary_koelectra/added_tokens.json')"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","\n","def compute_metrics(pred):\n","    labels = pred.label_ids\n","    preds = pred.predictions.argmax(-1)\n","    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n","    acc = accuracy_score(labels, preds)\n","    return {\n","        'accuracy': acc,\n","        'precision': precision,\n","        'recall': recall,\n","        'f1': f1,\n","    }\n","\n","# 평가 결과 출력\n","metrics = trainer.evaluate(eval_dataset=val_dataset)\n","print(f\"Accuracy: {metrics['eval_accuracy']}\")\n","print(f\"Precision: {metrics['eval_precision']}\")\n","print(f\"Recall: {metrics['eval_recall']}\")\n","print(f\"F1-score: {metrics['eval_f1']}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":110},"id":"KWP5WcFATOFs","executionInfo":{"status":"ok","timestamp":1728127040919,"user_tz":-540,"elapsed":44247,"user":{"displayName":"백현지","userId":"02510457579208942463"}},"outputId":"da4386d2-d45c-4215-937b-4426a09dadec"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [13/13 00:40]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.69\n","Precision: 0.8653846153846154\n","Recall: 0.45\n","F1-score: 0.5921052631578947\n"]}]},{"cell_type":"code","source":["# 테스트를 위한 텍스트 입력 및 토큰화\n","test_text = input()\n","inputs = tokenizer(test_text, return_tensors=\"pt\", truncation=True, padding=True, max_length=256)\n","\n","# 모델을 사용한 예측\n","outputs = model(**inputs)\n","predictions = torch.argmax(outputs.logits, dim=-1)\n","\n","# 결과 라벨 출력\n","label = predictions.item()\n","print(f\"예측된 라벨: {label}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kLHQ7HuFTn8G","executionInfo":{"status":"ok","timestamp":1728127190350,"user_tz":-540,"elapsed":3543,"user":{"displayName":"백현지","userId":"02510457579208942463"}},"outputId":"47dee074-0a2e-4181-a3d8-96c851fcadfb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(엑스포츠뉴스 잠실, 박지영 기자) 5일 오후 서울 송파구 잠실야구장에서 열린 '2024 신한 SOL Bank KBO 포스트시즌' KT 위즈와 LG 트윈스의 준플레이오프 1차전 경기, 5회초 KT 선두타자 황재균이 헛스윙 삼진 아웃으로 물러나고 있다.  박지영 기자 jypark@xportsnews.com\n","예측된 라벨: 1\n"]}]},{"cell_type":"code","source":["# 테스트를 위한 텍스트 입력 및 토큰화\n","test_text = input()\n","inputs = tokenizer(test_text, return_tensors=\"pt\", truncation=True, padding=True, max_length=256)\n","\n","# 모델을 사용한 예측\n","outputs = model(**inputs)\n","predictions = torch.argmax(outputs.logits, dim=-1)\n","\n","# 결과 라벨 출력\n","label = predictions.item()\n","print(f\"예측된 라벨: {label}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OdG7msKWaGfr","executionInfo":{"status":"ok","timestamp":1728127253743,"user_tz":-540,"elapsed":4010,"user":{"displayName":"백현지","userId":"02510457579208942463"}},"outputId":"2ec8a8a6-3e06-4d42-bda0-d4f5dd7b6c89"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["정상 네이버페이 창 결제방식 다양, 피싱 사이트 ‘일반결제와 네이버페이 간편결제’ 두 가지만 서비스 피싱 사이트에서 무통장입금 거래 선택시 사기 계좌로 연결, 송금 시 물품 수령 불가능 누리랩, 네이버페이 피싱 사이트 분석 보고서 발표  [보안뉴스 김영명 기자] 네이버(NAVER)의 결제 시스템인 네이버페이(NAVER PAY)를 이용한 네이버쇼핑은 최근 쿠팡을 넘어 국내 점유율 22%를 기록하며 전자상거래 분야 시장점유율에서 1위를 차지했다. 네이버쇼핑 서비스는 물품의 구매와 결제 등을 매우 편리하게 만들어 주는 시스템이자 서비스다. 하지만 최근 결제 창 등을 사칭해 사용자의 정보 탈취 혹은 사기 행위를 벌이는 피싱 사이트가 다수 발견되어 사용자들의 주의가 필요하다.   ▲네이버페이 피싱 사이트의 최초 구성 화면[자료=누리랩 보안팀]  보안전문기업 누리랩이 발표한 ‘네이버페이 피싱 사이트 분석 보고서’를 살펴보면 올해 8월에 파악된 피싱 사이트의 URL 건수는 중복을 제외하고 전달보다 4만 7,177건이 증가한 8만 5,768건으로 나타났다.  해당 피싱 사이트에 처음으로 접속하면 사기 물품의 간략한 구매 정보와 함께 배송지를 등록하라는 메시지가 출력된다. 네이버쇼핑 구매 물품의 정식 결제 창과 매우 비슷한 사이트 구성을 띄고 있지만, 이를 자세히 살펴보면 여러 가지 차이점이 존재한다.  첫 번째 차이는 바로 사이트의 URL이다. 네이버페이의 공식 결제창 URL은 ‘or***.pay.nav**.com’ 형식이다. 하지만 피싱 사이트의 URL은 ‘naverpay-****.cafe’와 ‘naverpay-page****.cafe’로 표기된다. 또한 네이버쇼핑 공식 사이트의 실제 결제 창에서는 URL의 패스, 파라미터, 프레그먼트 등의 구성 요소에 판매자 상점 정보와 구매 물품 정보 등이 포함돼 있다. 하지만 피싱 사이트의 URL에서는 해당 정보 등을 확인할 수 없다. 따라서 URL 구성 화면부터 해당 사이트는 피싱이나 사기와 같은 악의적 행위를 목적으로 한 사이트임을 알 수 있다.\n","예측된 라벨: 0\n"]}]},{"cell_type":"code","source":["# 이제 이 모델로 데이터 필터링해서 1로 분류된 데이터 버리기"],"metadata":{"id":"dyL-aPbLBP45"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1bcWkgxg8zbccxxi7mMqCILyx2WCHBeor","timestamp":1727948330241},{"file_id":"1aqKgcNSifEsskejM5dSYeWbPYMnrY7gf","timestamp":1727827058219},{"file_id":"1rfaV-edX0QYlEJAouZAnGOro5cKhCzcQ","timestamp":1727632887793}],"machine_shape":"hm","mount_file_id":"1bcWkgxg8zbccxxi7mMqCILyx2WCHBeor","authorship_tag":"ABX9TyML7AblUPdiCUH3K6XLr+ID"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}